{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "# Importing model, data loaders and other utilities\n",
    "from models.neo_phurie import NeoPHURIE\n",
    "from models.oracle_phurie import OraclePHURIE\n",
    "from dataLoaders.embedding_loader import EmbeddingDataset\n",
    "from utils import OneCycleLR\n",
    "\n",
    "# Constants\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 32\n",
    "DATASET_PATH = \"./datasets/embedding_dataset_2015.data\"\n",
    "INTENSITY_STD = 23.12\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, \n",
    "          num_epochs, \n",
    "          learning_rate= (1e-5, 1e-4), \n",
    "          regularization_rate = 0, \n",
    "          train_years = [],\n",
    "          verbose = False):\n",
    "    \n",
    "    # Memory management\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Training Dataset\n",
    "    train_loader = DataLoader(EmbeddingDataset(DATASET_PATH, train_years), batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    # Training optimizer, scheduler and loss\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate[0], weight_decay=regularization_rate)\n",
    "    scheduler = OneCycleLR(optimizer, num_steps = num_epochs*len(train_loader), lr_range=learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Scaler for mixed-precision training\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    # Moving model to compute device\n",
    "    model.to(device)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        train_squared_residuals = 0.0\n",
    "        \n",
    "        # Progress bar\n",
    "        pbar = tqdm(enumerate(train_loader, 0), total = len(train_loader), unit = \"pairs\", unit_scale=BATCH_SIZE, disable=not verbose)\n",
    "        \n",
    "        # Iterate through batches in training dataset\n",
    "        for i, data in pbar:\n",
    "            x, y = data\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with autocast():\n",
    "                outputs = model(x.to(device))\n",
    "                loss = criterion(outputs, y.to(device))\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "\n",
    "            # print statistics\n",
    "            train_squared_residuals += nn.functional.mse_loss(outputs, y.to(device)).item() * BATCH_SIZE\n",
    "            pbar.set_description(f\"[Epoch {epoch + 1}]: Training RMSE = {sqrt(train_squared_residuals / ((i + 1) * BATCH_SIZE)):.4f}\")\n",
    "\n",
    "        train_mse = train_squared_residuals / len(train_loader.dataset)\n",
    "                \n",
    "        if verbose:\n",
    "            print(f\"[Epoch {epoch + 1}]: Training RMSE = {sqrt(train_mse):.4f}\")\n",
    "\n",
    "        # Memory management\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 1]: Training RMSE = 0.1411: 100%|██████████| 52192/52192 [00:28<00:00, 1850.43pairs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1]: Training RMSE = 0.1411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 2]: Training RMSE = 0.1279: 100%|██████████| 52192/52192 [00:28<00:00, 1848.28pairs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2]: Training RMSE = 0.1279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 3]: Training RMSE = 0.1268: 100%|██████████| 52192/52192 [00:26<00:00, 1963.16pairs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3]: Training RMSE = 0.1268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 4]: Training RMSE = 0.1232: 100%|██████████| 52192/52192 [00:27<00:00, 1881.02pairs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4]: Training RMSE = 0.1233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 5]: Training RMSE = 0.1163: 100%|██████████| 52192/52192 [00:27<00:00, 1876.24pairs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5]: Training RMSE = 0.1164\n"
     ]
    }
   ],
   "source": [
    "oracle = OraclePHURIE()\n",
    "train_model(oracle,\n",
    "    num_epochs = 5,\n",
    "    learning_rate = (1e0, 1e1),\n",
    "    regularization_rate = 1e-5,\n",
    "    train_years = range(2001, 2015),\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_oracle(oracle,\n",
    "                decoder,\n",
    "                testing_years = [],\n",
    "                max_forecast_steps = 10,\n",
    "                useMeasuredIntensities = False):\n",
    "\n",
    "    decoder.to(device)\n",
    "    decoder.eval()\n",
    "    oracle.to(device)\n",
    "    oracle.eval()\n",
    "\n",
    "    testing_dataset = EmbeddingDataset(DATASET_PATH, testing_years)\n",
    "\n",
    "    errors_at_offset = {}\n",
    "    for l in range(1, max_forecast_steps+1):\n",
    "        errors_at_offset[l] = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for hurricane in tqdm(testing_dataset.get_hurricanes(), total = len([h for h in testing_dataset.get_hurricanes()])):\n",
    "            x, y = hurricane\n",
    "            x, y = x.to(device), y.to(device)\n",
    "                   \n",
    "            # Get NeoPHURIE predictions for intensities \n",
    "            pred_y = decoder.predict_from_embedding(x)\n",
    "            \n",
    "            for start_idx in range(x.shape[0] - 2):\n",
    "                \n",
    "                # Embedding with which to start forecasting\n",
    "                embedding_1 = torch.clone(torch.cat([x[start_idx], \n",
    "                                                     y[start_idx] if useMeasuredIntensities else pred_y[start_idx]])).to(device)\n",
    "                embedding_2 = torch.clone(torch.cat([x[start_idx+1], \n",
    "                                                     y[start_idx+1] if useMeasuredIntensities else pred_y[start_idx+1]])).to(device)\n",
    "                \n",
    "                for offset in range(1, min(max_forecast_steps+1, x.shape[0] - start_idx - 1)):\n",
    "                    \n",
    "                    pred_embedding = oracle(torch.cat([embedding_1, embedding_2]).to(device))\n",
    "                    pred_intensity = pred_embedding[1152]\n",
    "                \n",
    "                    errors_at_offset[offset].append(abs(pred_intensity.item() - y[start_idx + offset + 1].item()) * INTENSITY_STD)\n",
    "                    \n",
    "                    embedding_1 = embedding_2\n",
    "                    embedding_2 = pred_embedding\n",
    "    \n",
    "    test_statistics = []\n",
    "    for l in range(1, max_forecast_steps+1):\n",
    "        test_statistics.append((np.mean(errors_at_offset[l]),\n",
    "                                np.quantile(errors_at_offset[l], 0.25),\n",
    "                                np.quantile(errors_at_offset[l], 0.5),\n",
    "                                np.quantile(errors_at_offset[l], 0.75)))\n",
    "        \n",
    "    return test_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:48<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecasting at 3 hours: MAE = 7.12 ; Q1 = 2.25 ; Median = 5.16 ; Q3 = 9.88\n",
      "Forecasting at 6 hours: MAE = 7.35 ; Q1 = 2.35 ; Median = 5.37 ; Q3 = 10.21\n",
      "Forecasting at 9 hours: MAE = 7.71 ; Q1 = 2.41 ; Median = 5.60 ; Q3 = 10.63\n",
      "Forecasting at 12 hours: MAE = 8.23 ; Q1 = 2.61 ; Median = 6.01 ; Q3 = 11.31\n",
      "Forecasting at 15 hours: MAE = 8.85 ; Q1 = 2.76 ; Median = 6.39 ; Q3 = 12.26\n",
      "Forecasting at 18 hours: MAE = 9.56 ; Q1 = 2.95 ; Median = 6.86 ; Q3 = 13.34\n",
      "Forecasting at 21 hours: MAE = 10.31 ; Q1 = 3.10 ; Median = 7.43 ; Q3 = 14.30\n",
      "Forecasting at 24 hours: MAE = 11.12 ; Q1 = 3.46 ; Median = 7.94 ; Q3 = 15.40\n",
      "Forecasting at 27 hours: MAE = 11.89 ; Q1 = 3.68 ; Median = 8.38 ; Q3 = 16.61\n",
      "Forecasting at 30 hours: MAE = 12.71 ; Q1 = 3.85 ; Median = 8.92 ; Q3 = 17.77\n",
      "Forecasting at 33 hours: MAE = 13.55 ; Q1 = 3.98 ; Median = 9.53 ; Q3 = 18.91\n",
      "Forecasting at 36 hours: MAE = 14.48 ; Q1 = 4.36 ; Median = 10.39 ; Q3 = 20.28\n",
      "Forecasting at 39 hours: MAE = 15.39 ; Q1 = 4.62 ; Median = 11.12 ; Q3 = 21.12\n",
      "Forecasting at 42 hours: MAE = 16.27 ; Q1 = 4.85 ; Median = 11.54 ; Q3 = 22.03\n",
      "Forecasting at 45 hours: MAE = 17.14 ; Q1 = 4.98 ; Median = 12.02 ; Q3 = 23.52\n",
      "Forecasting at 48 hours: MAE = 18.01 ; Q1 = 5.35 ; Median = 12.71 ; Q3 = 24.81\n",
      "Forecasting at 51 hours: MAE = 18.80 ; Q1 = 5.52 ; Median = 13.14 ; Q3 = 25.98\n",
      "Forecasting at 54 hours: MAE = 19.53 ; Q1 = 5.69 ; Median = 13.81 ; Q3 = 27.39\n",
      "Forecasting at 57 hours: MAE = 20.25 ; Q1 = 6.05 ; Median = 14.41 ; Q3 = 29.11\n",
      "Forecasting at 60 hours: MAE = 20.99 ; Q1 = 6.14 ; Median = 14.86 ; Q3 = 30.77\n",
      "Forecasting at 63 hours: MAE = 21.73 ; Q1 = 6.31 ; Median = 15.35 ; Q3 = 32.34\n",
      "Forecasting at 66 hours: MAE = 22.44 ; Q1 = 6.34 ; Median = 16.15 ; Q3 = 34.20\n",
      "Forecasting at 69 hours: MAE = 23.13 ; Q1 = 6.58 ; Median = 16.85 ; Q3 = 35.53\n",
      "Forecasting at 72 hours: MAE = 23.78 ; Q1 = 6.60 ; Median = 17.60 ; Q3 = 36.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "decoder = NeoPHURIE()\n",
    "decoder.load_state_dict(torch.load(\"./checkpoints/neo_phurie_2015.pt\"))\n",
    "\n",
    "statistics = test_oracle(oracle,\n",
    "                         decoder,\n",
    "                         testing_years = [2015],\n",
    "                         max_forecast_steps=24,\n",
    "                         useMeasuredIntensities=False)\n",
    "\n",
    "for i, stat in enumerate(statistics):\n",
    "    print(f\"Forecasting at {3*i + 3} hours: MAE = {stat[0]:.2f} ; Q1 = {stat[1]:.2f} ; Median = {stat[2]:.2f} ; Q3 = {stat[3]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
